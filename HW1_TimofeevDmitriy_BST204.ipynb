{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgGAuXNSizcj"
      },
      "source": [
        "# Домашнее задание №1: линейная регрессия (10 баллов).\n",
        "\n",
        "Некоторые задания будут по вариантам (всего 4 варианта). Чтобы выяснить свой вариант, посчитайте количество букв в своей фамилии, возьмете остаток от деления на 4 и прибавьте 1.\n",
        "\n",
        "#### Напишите сюда свой вариант: 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GCz49gEZizck"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOk8iY3Sizck"
      },
      "source": [
        "## Многомерная линейная регрессия из sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksZbiHogizck"
      },
      "source": [
        "Применим многомерную регрессию из sklearn для стандартного датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khbOt9Y_izck",
        "outputId": "c1d92c3d-0c23-4780-f6b9-8112949cf1ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 100) (10000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples = 10000)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, random_state=1337)"
      ],
      "metadata": {
        "id": "X1mmtjjOzKUc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPMmSHi-izcl"
      },
      "source": [
        "У нас 10000 объектов и 100 признаков. Для начала решим задачу аналитически \"из коробки\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s8RuRvPizcl",
        "outputId": "75254b0e-40c8-4920-8230-f2a5022c4d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3479427223196442e-25\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "print(mean_squared_error(y_test, reg.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMn6DoaLizcm"
      },
      "source": [
        "Теперь попробуем обучить линейную регрессию методом градиентного спуска \"из коробки\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYU--nGnizcn",
        "outputId": "206fdb87-4318-407b-c15f-37cc81a12dce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6547360356996457e-10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6.81118488e+01,  5.67527667e+00, -8.35167982e-07, -3.32867378e-07,\n",
              "       -2.78065121e-07,  6.92378200e-07, -9.58721608e-07,  6.50213361e-07,\n",
              "        1.47613532e-06,  1.33472433e-06, -2.18038216e-06,  5.04446692e-07,\n",
              "       -4.10664980e-07,  1.40009224e-06, -8.50566469e-07, -3.99961021e-07,\n",
              "       -1.07904758e-06,  9.20855869e+01,  6.55280005e+01,  5.80255519e-07,\n",
              "        1.10383518e-07,  1.55268484e-07,  1.17040809e-07, -1.37322697e-06,\n",
              "        7.51070887e-07, -9.27848448e-07,  1.43019224e-06,  2.07070380e-06,\n",
              "       -1.98133798e-06, -9.30261090e-07, -4.81945394e-06, -4.18835305e-07,\n",
              "       -5.99349079e-07,  5.46281837e+01, -3.32393490e-06, -1.79885292e-06,\n",
              "       -1.13637556e-06,  5.84001657e+01,  1.52491238e-06, -3.45610686e-07,\n",
              "       -2.21500776e-06,  3.40203824e-07,  9.19122358e-07, -1.57305345e-06,\n",
              "       -4.79378197e-07,  9.17819169e+00, -5.76264891e-07, -3.19130331e-06,\n",
              "        1.24278893e-06, -2.79236012e-06, -2.29551087e-06, -8.65197996e-07,\n",
              "       -3.67843111e-07, -3.20294319e-06, -9.80807718e-08,  5.40761534e-07,\n",
              "        6.00012446e-07,  1.74201748e-06,  1.90891484e-06, -7.50193833e-07,\n",
              "       -2.12890386e-06,  1.04969206e-06, -1.73521438e-06,  1.59988458e-06,\n",
              "       -2.46484800e-06, -2.42489137e-06,  7.20324090e-07, -2.79695162e-07,\n",
              "       -5.36591309e-07,  6.48368810e-07, -8.47222484e-07,  1.66897077e+00,\n",
              "       -2.08354059e-07,  9.74634969e-07,  1.96516487e-06,  1.21503476e-07,\n",
              "        9.37344343e+01, -8.79979411e-07, -2.45934450e-06,  3.23511653e-07,\n",
              "        1.47975634e-06, -1.70232253e-06, -2.30230130e-06,  4.53270874e-06,\n",
              "       -1.83492084e-06, -4.09851761e-06,  3.03870723e-07, -1.77304986e-06,\n",
              "       -1.04431461e-06,  2.63169212e-06,  2.03611460e-06,  1.17744149e-07,\n",
              "       -1.70226533e-06,  7.56649937e-07,  1.33385175e-07,  7.60510540e+01,\n",
              "        2.45607286e-07,  5.63365533e-07, -1.08385668e-06,  5.60280053e-08])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "reg_sgd = SGDRegressor(alpha=1e-15).fit(X_train, y_train)\n",
        "print(mean_squared_error(y_test, reg_sgd.predict(X_test)))\n",
        "reg_sgd.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoI9RBGXizcn"
      },
      "source": [
        "***Задание 1 (1 балл).*** Объясните, чем вызвана разница в значениях двух полученных значений метрики?\n",
        "\n",
        "Метод градиентного спуска показывает себя хуже(но не сильно), потому что из-за инциализации рандомной точки мы можем попасть в локальный, а не глобальный минимум. При обучении метода линейной регрессии мы обучаем модель так, чтобы она сразу минимизировала среднеквадратическую ошибку\n",
        "\n",
        "***Задание 2 (1 балл).*** Подберите гиперпараметры в методе градиентного спуска так, чтобы значение MSE было близко к значению MSE, полученному при обучении LinearRegression.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmYS7zRPizcn"
      },
      "source": [
        "## Ваша многомерная линейная регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdglJeUGizcn"
      },
      "source": [
        "***Задание 3 (5 баллов)***. Напишите собственную многомерную линейную регрессию, оптимизирующую MSE методом *градиентного спуска*. Для этого используйте шаблонный класс.\n",
        "\n",
        "Критерий останова: либо норма разности весов на текущей и предыдущей итерациях меньше определенного значения (первый и третий варианты), либо модуль разности функционалов качества (MSE) на текущей и предыдущей итерациях меньше определенного значения (второй и четвертый варианты). Также предлагается завершать обучение в любом случае, если было произведено слишком много итераций.\n",
        "\n",
        "***Задание 4 (2 балла)***. Добавьте l1 (первый и четвертый варианты) или l2 (второй и третий варианты) регуляризацию."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class sLinearRegression(object):\n",
        "    def __init__(self, alpha=0.01, l_ratio=0.00001, tol=1e-4, max_iter=1000):\n",
        "        '''\n",
        "        Для начала необходимо инициализировать параметры\n",
        "        alpha - это learning rate или шаг обучения\n",
        "        l_ratio - параметр регуляризации\n",
        "        tol - значение для критерия останова\n",
        "        max_iter - максимальное количество итераций обучения\n",
        "        '''\n",
        "        self.alpha = alpha\n",
        "        self.l_ratio = l_ratio\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "        self.weights, self.bias = None, None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Метод для обучения линейной регрессии\n",
        "        X - матрица признаков\n",
        "        y - вектор правильных ответов\n",
        "        '''\n",
        "\n",
        "        # Инициализируем веса значениями\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "        self.bias = 0\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            # Рассчитываем предсказания\n",
        "            predictions = np.dot(X, self.weights) + self.bias\n",
        "\n",
        "            # Вычисляем ошибку\n",
        "            error = predictions - y\n",
        "\n",
        "            # Рассчитываем градиент с L2-регуляризацией\n",
        "            gradient = (2 / X.shape[0]) * np.dot(X.T, error) + 2 * self.l_ratio * self.weights\n",
        "            gradient_bias = (2 / X.shape[0]) * np.sum(error)\n",
        "\n",
        "            # Обновляем веса с использованием градиентного спуска\n",
        "            self.weights -= self.alpha * gradient\n",
        "            self.bias -= self.alpha * gradient_bias\n",
        "\n",
        "            # Проверяем критерий останова\n",
        "            if np.linalg.norm(gradient) < self.tol:\n",
        "                break\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Метод для предсказаний линейной регрессии\n",
        "        X - матрица признаков\n",
        "        '''\n",
        "\n",
        "        return np.dot(X, self.weights) + self.bias\n"
      ],
      "metadata": {
        "id": "Y02_jxkfqUWl"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(my_reg.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6aMB3_sc69c",
        "outputId": "318a6291-ff3c-416d-a165-83065fb9e68f"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(y_test, my_reg.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp6jlOdPqlL7",
        "outputId": "86e9cf0b-7cec-4b3f-e06e-7b733447fd26"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.356061707440644e-06"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "H3_HtgURizcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a600d28-2340-4ea2-b73f-53463d131c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are amazing! Great work!\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "my_reg = sLinearRegression(alpha=0.1, max_iter=10000)\n",
        "my_reg.fit(X_train, y_train)\n",
        "assert mean_squared_error(y_test, my_reg.predict(X_test)) < 1e-3\n",
        "print('You are amazing! Great work!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZynHUp5izcq"
      },
      "source": [
        "***Задание 5 (1 балл)***. Обучите линейную регрессию из коробки с l1-регуляризацией (from sklearn.linear_model import Lasso, первый и четвертый варианты) или с l2-регуляризацией (from sklearn.linear_model import Ridge, второй и третий варианты) с значением параметра регуляризации 0.1. Обучите вашу линейную регрессию с тем же значением параметра регуляризации и сравните результаты. Сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "-bS6J-vfizcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ab3fba-82ac-4eb5-8cbf-1dde43e11b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE для Ridge 0.00010602236561537249\n",
            "MSE для собственной регрессии 342.80785239530763\n"
          ]
        }
      ],
      "source": [
        "#your code here\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "r_lr = Ridge(alpha=0.1)\n",
        "r_lr.fit(X_train, y_train)\n",
        "print(f'MSE для Ridge', mean_squared_error(y_test, r_lr.predict(X_test)))\n",
        "print(f'MSE для собственной регрессии', mean_squared_error(y_test, my_reg2.predict(X_test)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_reg2 = sLinearRegression(alpha=0.01, max_iter=10000, l_ratio=0.1)\n",
        "my_reg2.fit(X_train, y_train)\n",
        "print(mean_squared_error(y_test, my_reg2.predict(X_test)))\n",
        "print('You are amazing! Great work!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4017VC3jwH_Z",
        "outputId": "f2650e1e-ca68-4578-df08-2cd1ad7b34ea"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "342.80785239530763\n",
            "You are amazing! Great work!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P8x1K67izcs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}